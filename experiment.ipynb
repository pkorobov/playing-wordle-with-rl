{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ca29be4-2dfb-4c66-adbd-df22d1f80d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from wordle_env import WordleEnv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dba69c13-dd8c-4077-8d8c-1ceabb702fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_allowed_letters(word_matrix, word_mask, position):\n",
    "    \"\"\"\n",
    "        word_matrix: torch.Tensor of size (num_words, word_length)\n",
    "        word_mask: torch.Tensor of size (batch_size, num_words)\n",
    "        position: int\n",
    "        \n",
    "        returns\n",
    "        \n",
    "        letters_mask: (batch_size, num_letters) -- mask of possible letters\n",
    "    \"\"\"\n",
    "    batch_size = word_mask.size(0)\n",
    "    word_matrix_expanded = word_matrix[:, position].unsqueeze(0).expand(batch_size, -1)\n",
    "    \n",
    "    # print(word_matrix[:, position].shape)\n",
    "    # print(word_matrix_expanded.shape)\n",
    "    # print(word_matrix[:, position].unsqueeze(1).shape)\n",
    "    \n",
    "    word_matrix_masked = (word_matrix_expanded * word_mask).long()    \n",
    "    letter_mask = torch.full(fill_value=False, size=(batch_size, num_letters))\n",
    "    letter_mask.scatter_(index=word_matrix_masked, dim=1, value=True)\n",
    "    letter_mask[:, 0] = 0\n",
    "    return letter_mask\n",
    "    return letter_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e150594f-d647-4231-8c31-c23f8c4c0953",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Categorical\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, letter_tokens, guess_tokens, emb_dim, hid_dim, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hid_dim = hid_dim\n",
    "        \n",
    "        self.letter_embedding = nn.Embedding(letter_tokens, emb_dim)\n",
    "        self.guess_state_embedding = nn.Embedding(guess_tokens, emb_dim)\n",
    "\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, letter_seq, state_seq):\n",
    "        letters_embedded = self.dropout(self.letter_embedding(letter_seq))\n",
    "        states_embedded = self.dropout(self.guess_state_embedding(state_seq))\n",
    "\n",
    "        outputs, (hidden, cell) = self.rnn(letters_embedded + states_embedded)\n",
    "        \n",
    "        #outputs = [src len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #outputs are always from the top hidden layer\n",
    "        \n",
    "        return hidden, cell\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, dropout=dropout)        \n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, cell):\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "                \n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        return prediction, hidden, cell\n",
    "\n",
    "\n",
    "\n",
    "class RNNAgent(nn.Module):\n",
    "    def __init__(self, letter_tokens, guess_tokens, emb_dim, hid_dim, output_dim, game_voc_matrix, output_len, sos_token, dropout=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = Encoder(letter_tokens, guess_tokens, emb_dim, hid_dim, dropout)\n",
    "        self.decoder = Decoder(output_dim, emb_dim, hid_dim, dropout)\n",
    "\n",
    "        modules = [nn.Linear(hid_dim, hid_dim), nn.ReLU(), nn.Linear(hid_dim, 1)]\n",
    "        self.V_head = nn.Sequential(*modules)\n",
    "        \n",
    "        self.letter_tokens = letter_tokens\n",
    "        self.game_voc_matrix = game_voc_matrix\n",
    "        self.output_len = output_len\n",
    "        self.sos_token = sos_token\n",
    "    \n",
    "    def forward(self, letter_seq, state_seq):        \n",
    "        # tensor to store decoder outputs\n",
    "        batch_size = letter_seq.shape[1]\n",
    "        logits = torch.zeros(self.output_len + 1, batch_size, self.letter_tokens)\n",
    "\n",
    "        hidden, cell = self.encoder(letter_seq, state_seq)\n",
    "\n",
    "        # compute V\n",
    "        values = self.V_head(hidden.squeeze())\n",
    "\n",
    "        # first input to the decoder is the <sos> tokens\n",
    "        input = torch.full(size=(batch_size,), fill_value=self.sos_token)\n",
    "        \n",
    "        letter_mask = torch.full(size=(batch_size, self.letter_tokens), fill_value=True)\n",
    "        word_mask = torch.full(size=(batch_size, self.game_voc_matrix.shape[0]), fill_value=True)\n",
    "\n",
    "        # logits: (seq_length, batch_size, num_classes)\n",
    "        \n",
    "        actions = torch.zeros(size=(batch_size, self.output_len), dtype=torch.long)\n",
    "        log_probs = torch.zeros(size=(batch_size,))\n",
    "        for t in range(1, self.output_len + 1):\n",
    "\n",
    "            # cur_logits: (batch_size, num_classes)\n",
    "            # actions: (batch_size,)\n",
    "            cur_logits, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            logits[t] = cur_logits\n",
    "\n",
    "            probs = F.softmax(cur_logits, dim=-1)\n",
    "\n",
    "            allowed_letters = get_allowed_letters(self.game_voc_matrix, word_mask, t-1)            \n",
    "            probs[~allowed_letters] = 0.0\n",
    "            actions_t = Categorical(probs=probs).sample()\n",
    "            \n",
    "            word_mask = word_mask & (self.game_voc_matrix[:, t - 1].unsqueeze(0) == actions_t.unsqueeze(1))\n",
    "\n",
    "            # keep which words are acceptable\n",
    "            cur_log_probs = torch.log(probs[range(batch_size), actions_t].clip(min=1e-12)).squeeze()\n",
    "\n",
    "            # letters_allowed_count = allowed_letters.sum(axis=-1)\n",
    "            # log_probs[letters_allowed_count > 1] += cur_log_probs[letters_allowed_count > 1]\n",
    "            log_probs += cur_log_probs\n",
    "            \n",
    "            actions[:, t-1] = actions_t\n",
    "            input = actions_t\n",
    "\n",
    "        return {\n",
    "            \"actions\": actions.cpu().numpy(),\n",
    "            # \"logits\": logits,\n",
    "            \"log_probs\": log_probs,\n",
    "            \"values\": values,\n",
    "        }\n",
    "    \n",
    "    def act(self, inputs):\n",
    "        '''\n",
    "        input:\n",
    "            inputs - numpy array, (batch_size x channels x width x height)\n",
    "        output: dict containing keys ['actions', 'logits', 'log_probs', 'values']:\n",
    "            'actions' - selected actions, numpy, (batch_size)\n",
    "            'log_probs' - log probs of selected actions, tensor, (batch_size)\n",
    "            'values' - critic estimations, tensor, (batch_size)\n",
    "        '''\n",
    "        inputs = torch.LongTensor(inputs)\n",
    "        letter_tokens, state_tokens = inputs[0], inputs[1]\n",
    "        outputs = self(letter_tokens, state_tokens)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0f0b37bd-961a-478b-9846-e96dfea6738f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test get_allowed_letters\n",
    "from wrappers import SequenceWrapper\n",
    "\n",
    "num_letters = 29\n",
    "\n",
    "env = WordleEnv()\n",
    "env = SequenceWrapper(env, sos_token=1)\n",
    "\n",
    "word_mask = torch.tensor([[True, False, False], [False, True, False]])\n",
    "\n",
    "present_letters = get_allowed_letters(torch.from_numpy(env.game_voc_matrix), word_mask, 3).to(torch.long)\n",
    "present_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98452bf7-aad9-4c49-ba47-11b5120910e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[INFO/Process-1] child process calling self.run()\n",
      "[INFO/Process-1] child process calling self.run()\n",
      "[INFO/Process-2] child process calling self.run()\n",
      "[INFO/Process-2] child process calling self.run()\n",
      "[DEBUG/MainProcess] created semlock with handle 88\n",
      "[DEBUG/MainProcess] created semlock with handle 89\n",
      "[DEBUG/MainProcess] created semlock with handle 90\n"
     ]
    }
   ],
   "source": [
    "from wrappers import nature_dqn_env\n",
    "import numpy as np\n",
    "\n",
    "env_2 = nature_dqn_env(nenvs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81765053-196a-4f1c-838d-fd98fc494f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0]]],\n",
       " \n",
       " \n",
       "        [[[0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0]]]], dtype=int32),\n",
       " array([0., 0.]),\n",
       " array([ True,  True]),\n",
       " ({}, {}))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_2.step(np.array([5, 5, 5, 5, 5]).reshape(1, -1).repeat(2, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce952f51-a44c-43a1-ae23-d6e260907214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "599f579b-aec7-4ff9-af16-405db1fa143b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizer import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "game_voc_matrix = torch.FloatTensor(env.game_voc_matrix)\n",
    "agent = RNNAgent(len(tokenizer.index2letter), len(tokenizer.index2guess_state), 64, 32, len(tokenizer.index2letter), output_len=5, sos_token=1, game_voc_matrix=game_voc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "59a8b101-c082-46ec-ad81-0bfccb6d950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "letter_tokens = torch.LongTensor(obs[0].reshape(-1, 1))\n",
    "state_tokens = torch.LongTensor(obs[1].reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "356d3aaa-281f-400d-a892-cfa4e8e40911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([array([[ 5, 20,  3, 16,  7]]), tensor([-16.4809], grad_fn=<AddBackward0>), tensor([0.0550], grad_fn=<AddBackward0>)])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_output = agent(letter_tokens, state_tokens).values()\n",
    "agent_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d5e5f6ed-b419-4cda-abeb-e4b69aaadef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from runners import EnvRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b7acf248-f722-48d6-bd9e-32999497a7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = EnvRunner(env, agent, nsteps=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fc271d40-8f68-45be-ad2f-9f99b8a33f21",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [133]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/wordle/runners.py:44\u001b[0m, in \u001b[0;36mEnvRunner.get_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnsteps):\n\u001b[1;32m     43\u001b[0m     observations\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_observation)\n\u001b[0;32m---> 44\u001b[0m     act \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatest_observation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactions\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m act:\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult of policy.act must contain \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactions\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     48\u001b[0m                          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut has keys \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(act\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[0;32mIn [126]\u001b[0m, in \u001b[0;36mRNNAgent.act\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    128\u001b[0m inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mLongTensor(inputs)\n\u001b[1;32m    129\u001b[0m letter_tokens, state_tokens \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;241m0\u001b[39m], inputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 130\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mletter_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rl/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [126]\u001b[0m, in \u001b[0;36mRNNAgent.forward\u001b[0;34m(self, letter_seq, state_seq)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, letter_seq, state_seq):        \n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# tensor to store decoder outputs\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m \u001b[43mletter_seq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     70\u001b[0m     logits \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_len \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mletter_tokens)\n\u001b[1;32m     72\u001b[0m     hidden, cell \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(letter_seq, state_seq)\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "runner.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7114cb21-1fcd-46f3-a7ef-5b68dcc072fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a61ceb-e91a-4500-9dd8-0d39fbbca3b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "81d41272-ca8e-45f6-9d94-a4e0140feab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 10\n",
    "\n",
    "for _ in range(num_episodes):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        letter_tokens, state_tokens = obs\n",
    "        letter_tokens, state_tokens = torch.from_numpy(letter_tokens), torch.from_numpy(state_tokens)\n",
    "        letter_tokens, state_tokens = letter_tokens.reshape(-1, 1), state_tokens.reshape(-1, 1)\n",
    "        action, logit = agent(letter_tokens, state_tokens)\n",
    "        if np.random.rand() > 0.5:\n",
    "            break\n",
    "        obs, reward, done, info = env.step(action.squeeze().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5c7a126a-cbf2-4ba4-b6e5-24da57ebbc7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, 21, 25, 17, 20,  6,  1,  0,  0,  0,  0,  0,  1,  0,  0,  0,\n",
       "         0,  0,  1,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  1,  0,\n",
       "         0,  0,  0,  0],\n",
       "       [ 1,  1,  1,  1,  1,  1,  1,  0,  0,  0,  0,  0,  1,  0,  0,  0,\n",
       "         0,  0,  1,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  1,  0,\n",
       "         0,  0,  0,  0]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "bd285469-0c57-4a6b-bac4-d8e639897b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21, 25, 17, 20,  6],\n",
       "       [ 5, 20,  3, 16,  7],\n",
       "       [18, 14,  3, 22,  7]], dtype=int32)"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.game_voc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ea46c8-4386-4b33-898d-2a080c08d30b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
