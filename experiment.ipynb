{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ca29be4-2dfb-4c66-adbd-df22d1f80d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from wordle_env import WordleEnv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8790781-9e0e-4f14-85af-c4b0b707bec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import RNNAgent, get_allowed_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6f1f613-ce69-44eb-b936-a42e59a93e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7f9a11d67e80>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab7ae835-d677-49c8-a9a3-3e5c55a6afd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "654f42ab-9d53-4d8c-93cc-6d6fdf8bff65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "[INFO/Process-2] child process calling self.run()\n",
      "[INFO/Process-1] child process calling self.run()\n",
      "[INFO/Process-2] child process calling self.run()\n",
      "[INFO/Process-1] child process calling self.run()\n",
      "[INFO/Process-3] child process calling self.run()\n",
      "[INFO/Process-3] child process calling self.run()\n",
      "[INFO/Process-4] child process calling self.run()\n",
      "[INFO/Process-4] child process calling self.run()\n",
      "[DEBUG/MainProcess] created semlock with handle 92\n",
      "[DEBUG/MainProcess] created semlock with handle 94\n",
      "[DEBUG/MainProcess] created semlock with handle 96\n",
      "/Users/pkorobov/opt/anaconda3/envs/rl/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "from wrappers import SequenceWrapper, ReshapeWrapper\n",
    "from wrappers import nature_dqn_env\n",
    "\n",
    "num_letters = 29\n",
    "env = nature_dqn_env(nenvs=4)\n",
    "from tokenizer import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "game_voc_matrix = torch.FloatTensor(env.game_voc_matrix)\n",
    "agent = RNNAgent(len(tokenizer.index2letter), len(tokenizer.index2guess_state), 32, 64, len(tokenizer.index2letter), output_len=5, sos_token=1, game_voc_matrix=game_voc_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5e5f6ed-b419-4cda-abeb-e4b69aaadef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG/MainProcess] Queue._start_thread()\n",
      "[DEBUG/MainProcess] doing self._thread.start()\n",
      "[DEBUG/MainProcess] starting thread to feed data to pipe\n",
      "[DEBUG/MainProcess] ... done self._thread.start()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory keys: dict_keys(['actions', 'log_probs', 'values', 'observations', 'rewards', 'dones'])\n",
      "Trajectory rewards: [array([0. , 0.4, 0. , 0.4]), array([0.4, 0. , 0. , 0.2]), array([0.4, 0.4, 0. , 0.2]), array([0. , 0.4, 0. , 0. ]), array([-0.4, -0.4, -0.2,  0.4]), array([ 0.8, -0.4, -0.4, -0.2])]\n",
      "Trajectory values: [tensor([-0.0755, -0.0755, -0.0755, -0.0755], grad_fn=<SqueezeBackward0>), tensor([-0.0755, -0.0755, -0.0755, -0.0755], grad_fn=<SqueezeBackward0>), tensor([-0.0755, -0.0755, -0.0755, -0.0755], grad_fn=<SqueezeBackward0>), tensor([-0.0754, -0.0755, -0.0755, -0.0754], grad_fn=<SqueezeBackward0>), tensor([-0.0744, -0.0751, -0.0751, -0.0752], grad_fn=<SqueezeBackward0>), tensor([-0.0741, -0.0758, -0.0769, -0.0761], grad_fn=<SqueezeBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "from runners import EnvRunner\n",
    "\n",
    "runner = EnvRunner(env, agent, nsteps=6)\n",
    "\n",
    "trajectory = runner.get_next()\n",
    "print(f\"Trajectory keys: {trajectory.keys()}\")\n",
    "print(f\"Trajectory rewards: {trajectory['rewards']}\")\n",
    "print(f\"Trajectory values: {trajectory['values']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "100440ad-20f6-4a7c-861d-69f0c610b129",
   "metadata": {},
   "outputs": [],
   "source": [
    "nenvs = 4\n",
    "\n",
    "# Sanity checks\n",
    "# assert 'logits' in trajectory, \"Not found: policy didn't provide logits\"\n",
    "assert 'log_probs' in trajectory, \"Not found: policy didn't provide log_probs of selected actions\"\n",
    "assert 'values' in trajectory, \"Not found: policy didn't provide critic estimations\"\n",
    "# assert trajectory['logits'][0].shape == (nenvs, n_actions), \"logits wrong shape\"\n",
    "assert trajectory['log_probs'][0].shape == (nenvs,), \"log_probs wrong shape\"\n",
    "assert trajectory['values'][0].shape == (nenvs,), \"values wrong shape\"\n",
    "\n",
    "for key in trajectory.keys():\n",
    "    assert len(trajectory[key]) == 6, \\\n",
    "    f\"something went wrong: 6 steps should have been done, got trajectory of length {len(trajectory[key])} for '{key}'\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "759a1871-242f-4b54-9c90-97f460977fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectory['values'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88e19c1-f4fb-4784-abd3-28c3f48d545b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30655394-01cf-4f27-ac5b-b9be27aa8e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComputeValueTargets:\n",
    "    def __init__(self, policy, gamma=0.75):\n",
    "        self.policy = policy\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def __call__(self, trajectory, latest_observation):\n",
    "        '''\n",
    "        This method should modify trajectory inplace by adding \n",
    "        an item with key 'value_targets' to it\n",
    "        \n",
    "        input:\n",
    "            trajectory - dict from runner\n",
    "            latest_observation - last state, numpy, (num_envs x channels x width x height)\n",
    "        '''\n",
    "        T = len(trajectory['rewards'])\n",
    "        targets = [None] * T\n",
    "        R = self.policy.act(latest_observation)['values']\n",
    "        for t in range(T - 1, -1, -1):\n",
    "            rewards = torch.FloatTensor(trajectory['rewards'][t]).to(DEVICE)\n",
    "            dones = torch.LongTensor(trajectory['dones'][t]).to(DEVICE)\n",
    "            R = rewards + (1 - dones) * self.gamma * R\n",
    "            targets[t] = R\n",
    "        trajectory['value_targets'] = targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e93e36f-dedd-4821-bc24-e63ae6564447",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MergeTimeBatch:\n",
    "    \"\"\" Merges first two axes typically representing time and env batch. \"\"\"\n",
    "    def __call__(self, trajectory, latest_observation):\n",
    "        trajectory['log_probs'] = torch.cat(trajectory['log_probs'], dim=0)\n",
    "        trajectory['values'] = torch.cat(trajectory['values'], dim=0)        \n",
    "        trajectory['value_targets'] = torch.cat(trajectory['value_targets'], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88ec9d2f-982b-4a4c-9804-b803b7178362",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = EnvRunner(env, agent, nsteps=6, transforms=[ComputeValueTargets(agent, gamma=0.9),\n",
    "                                                      MergeTimeBatch()])\n",
    "trajectory = runner.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c14f2b9-3c6d-4f47-abbd-7a552da1e1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "class A2C:\n",
    "    def __init__(self, policy, optimizer, value_loss_coef=0.25, entropy_coef=0.01, max_grad_norm=0.5):\n",
    "        self.policy = policy\n",
    "        self.optimizer = optimizer\n",
    "        self.value_loss_coef = value_loss_coef\n",
    "        self.entropy_coef = entropy_coef\n",
    "        self.max_grad_norm = max_grad_norm\n",
    "    \n",
    "    def loss(self, trajectory, write):\n",
    "        # compute all losses\n",
    "        # do not forget to use weights for critic loss and entropy loss\n",
    "\n",
    "        targets = trajectory['value_targets'].to(DEVICE).detach()\n",
    "        values = trajectory['values'].to(DEVICE)\n",
    "        log_probs = trajectory['log_probs'].to(DEVICE)\n",
    "        value_loss = (targets - values).pow(2).mean()\n",
    "        \n",
    "        # TODO: recompute\n",
    "        entropy_loss = 0.0 # (log_probs * torch.exp(log_probs)).mean()\n",
    "        \n",
    "        advantage = (targets - values).detach()\n",
    "        policy_loss = -(log_probs * advantage).mean()\n",
    "        \n",
    "        \n",
    "        # log all losses\n",
    "        write('losses', {\n",
    "            'policy loss': policy_loss,\n",
    "            'critic loss': value_loss,\n",
    "            'entropy loss': entropy_loss\n",
    "        })\n",
    "        \n",
    "        # additional logs\n",
    "        write('critic/advantage', advantage.mean())\n",
    "        write('critic/values', {\n",
    "            'value predictions': values.mean(),\n",
    "            'value targets': targets.mean(),\n",
    "        })\n",
    "        \n",
    "        # return scalar loss\n",
    "        return policy_loss + self.value_loss_coef * value_loss + self.entropy_coef * entropy_loss               \n",
    "\n",
    "    def train(self, runner):\n",
    "        # collect trajectory using runner\n",
    "        # compute loss and perform one step of gradient optimization\n",
    "        # do not forget to clip gradients\n",
    "        \n",
    "        trajectory = runner.get_next()\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        loss = self.loss(trajectory, runner.write)\n",
    "        loss.backward()\n",
    "        grad_norm = clip_grad_norm_(self.policy.parameters(), self.max_grad_norm)\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        runner.write('gradient norm', grad_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c361901-50ac-439b-8854-3852149c8a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO/Process-2] process shutting down\n",
      "[INFO/Process-2] process shutting down\n",
      "[INFO/Process-4] process shutting down\n",
      "[INFO/Process-4] process shutting down\n",
      "[DEBUG/Process-2] running all \"atexit\" finalizers with priority >= 0\n",
      "[INFO/Process-1] process shutting down\n",
      "[DEBUG/Process-2] running all \"atexit\" finalizers with priority >= 0\n",
      "[INFO/Process-1] process shutting down\n",
      "[DEBUG/Process-4] running all \"atexit\" finalizers with priority >= 0\n",
      "[DEBUG/Process-4] running all \"atexit\" finalizers with priority >= 0\n",
      "[DEBUG/Process-2] running the remaining \"atexit\" finalizers\n",
      "[DEBUG/Process-2] running the remaining \"atexit\" finalizers\n",
      "[DEBUG/Process-1] running all \"atexit\" finalizers with priority >= 0\n",
      "[DEBUG/Process-4] running the remaining \"atexit\" finalizers\n",
      "[DEBUG/Process-1] running all \"atexit\" finalizers with priority >= 0\n",
      "[DEBUG/Process-4] running the remaining \"atexit\" finalizers\n",
      "[DEBUG/Process-1] running the remaining \"atexit\" finalizers\n",
      "[DEBUG/Process-1] running the remaining \"atexit\" finalizers\n",
      "[INFO/Process-4] process exiting with exitcode 0\n",
      "[INFO/Process-4] process exiting with exitcode 0\n",
      "[INFO/Process-1] process exiting with exitcode 0\n",
      "[INFO/Process-1] process exiting with exitcode 0\n",
      "[INFO/Process-2] process exiting with exitcode 0\n",
      "[INFO/Process-2] process exiting with exitcode 0\n",
      "[INFO/Process-3] process shutting down\n",
      "[INFO/Process-3] process shutting down\n",
      "[DEBUG/Process-3] running all \"atexit\" finalizers with priority >= 0\n",
      "[DEBUG/Process-3] running all \"atexit\" finalizers with priority >= 0\n",
      "[DEBUG/Process-3] running the remaining \"atexit\" finalizers\n",
      "[DEBUG/Process-3] running the remaining \"atexit\" finalizers\n",
      "[INFO/Process-3] process exiting with exitcode 0\n",
      "[INFO/Process-3] process exiting with exitcode 0\n"
     ]
    }
   ],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a067a006-8a35-41ed-bc87-ffdad564182d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "[INFO/Process-6] child process calling self.run()\n",
      "[INFO/Process-6] child process calling self.run()\n",
      "[INFO/Process-5] child process calling self.run()\n",
      "[INFO/Process-5] child process calling self.run()\n",
      "[INFO/Process-8] child process calling self.run()\n",
      "[INFO/Process-8] child process calling self.run()\n",
      "[INFO/Process-7] child process calling self.run()\n",
      "[INFO/Process-7] child process calling self.run()\n",
      "[DEBUG/MainProcess] created semlock with handle 105\n",
      "[DEBUG/MainProcess] created semlock with handle 107\n",
      "[DEBUG/MainProcess] created semlock with handle 114\n"
     ]
    }
   ],
   "source": [
    "from wordle_env import WordleEnv\n",
    "from wrappers import SequenceWrapper, ReshapeWrapper, TensorboardSummaries\n",
    "from wrappers import nature_dqn_env\n",
    "\n",
    "# env = WordleEnv()\n",
    "# env = SequenceWrapper(env, sos_token=1)\n",
    "# env = ReshapeWrapper(env)\n",
    "# env = TensorboardSummaries(env, prefix='wordle')\n",
    "\n",
    "env = nature_dqn_env(nenvs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2ea46c8-4386-4b33-898d-2a080c08d30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Level 5/MainProcess] finalizer calling <function close_fds at 0x7f9a12b9ed30> with args [90, 95] and kwargs {}\n",
      "[Level 5/MainProcess] finalizer calling <function close_fds at 0x7f9a12b9ed30> with args [88, 93] and kwargs {}\n",
      "[Level 5/MainProcess] finalizer calling <function close_fds at 0x7f9a12b9ed30> with args [87, 91] and kwargs {}\n",
      "[Level 5/MainProcess] finalizer calling <function close_fds at 0x7f9a12b9ed30> with args [85, 89] and kwargs {}\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import RMSprop\n",
    "\n",
    "nenvs = 4\n",
    "nsteps = 10\n",
    "total_steps = 10 ** 6\n",
    "\n",
    "# env = nature_dqn_env(\"SpaceInvadersNoFrameskip-v4\", nenvs=nenvs)\n",
    "# n_actions = env.action_space.spaces[0].n\n",
    "obs = env.reset()\n",
    "\n",
    "# model = Model(obs.shape[1:], n_actions).to(DEVICE)\n",
    "policy = RNNAgent(\n",
    "    len(tokenizer.index2letter), \n",
    "    len(tokenizer.index2guess_state), \n",
    "    32, 128, \n",
    "    len(tokenizer.index2letter), \n",
    "    output_len=5, \n",
    "    sos_token=1, \n",
    "    game_voc_matrix=game_voc_matrix\n",
    ")\n",
    "\n",
    "runner = EnvRunner(env, policy, nsteps=nsteps, transforms=[ComputeValueTargets(policy),\n",
    "                                                      MergeTimeBatch()])\n",
    "optimizer = RMSprop(policy.parameters(), 7e-4)\n",
    "a2c = A2C(policy, optimizer, max_grad_norm=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a4fc01-bdcb-42e6-a7d7-510d03260047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04f3e96e-2341-4ba6-a778-05ceb5dd6e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG/MainProcess] created semlock with handle 77\n",
      "  0%|                                                                           | 0/25001 [00:00<?, ?it/s][DEBUG/MainProcess] Queue._start_thread()\n",
      "[DEBUG/MainProcess] doing self._thread.start()\n",
      "[DEBUG/MainProcess] starting thread to feed data to pipe\n",
      "[DEBUG/MainProcess] ... done self._thread.start()\n",
      "[DEBUG/MainProcess] created semlock with handle 87\n",
      "[DEBUG/MainProcess] created semlock with handle 88\n",
      "[DEBUG/MainProcess] created semlock with handle 89\n",
      "[DEBUG/MainProcess] Queue._start_thread()\n",
      "[DEBUG/MainProcess] doing self._thread.start()\n",
      "[DEBUG/MainProcess] starting thread to feed data to pipe\n",
      "[DEBUG/MainProcess] ... done self._thread.start()\n",
      "[DEBUG/MainProcess] created semlock with handle 119\n",
      "[DEBUG/MainProcess] created semlock with handle 120\n",
      "[DEBUG/MainProcess] created semlock with handle 121\n",
      "[DEBUG/MainProcess] Queue._start_thread()\n",
      "[DEBUG/MainProcess] doing self._thread.start()\n",
      "[DEBUG/MainProcess] starting thread to feed data to pipe\n",
      "[DEBUG/MainProcess] ... done self._thread.start()\n",
      "[DEBUG/MainProcess] created semlock with handle 127\n",
      "[DEBUG/MainProcess] created semlock with handle 128\n",
      "[DEBUG/MainProcess] created semlock with handle 129\n",
      "[DEBUG/MainProcess] Queue._start_thread()\n",
      "[DEBUG/MainProcess] doing self._thread.start()\n",
      "[DEBUG/MainProcess] starting thread to feed data to pipe\n",
      "[DEBUG/MainProcess] ... done self._thread.start()\n",
      "[DEBUG/MainProcess] created semlock with handle 135\n",
      "[DEBUG/MainProcess] created semlock with handle 136\n",
      "[DEBUG/MainProcess] created semlock with handle 137\n",
      "[DEBUG/MainProcess] Queue._start_thread()\n",
      "[DEBUG/MainProcess] doing self._thread.start()\n",
      "[DEBUG/MainProcess] starting thread to feed data to pipe\n",
      "[DEBUG/MainProcess] ... done self._thread.start()\n",
      "[DEBUG/MainProcess] created semlock with handle 143\n",
      "[DEBUG/MainProcess] created semlock with handle 144\n",
      "[DEBUG/MainProcess] created semlock with handle 145\n",
      "[DEBUG/MainProcess] Queue._start_thread()\n",
      "[DEBUG/MainProcess] doing self._thread.start()\n",
      "[DEBUG/MainProcess] starting thread to feed data to pipe\n",
      "[DEBUG/MainProcess] ... done self._thread.start()\n",
      " 13%|███████▌                                                   | 3216/25001 [1:59:12<13:29:00,  2.23s/it][INFO/Process-7] process shutting down\n",
      "[INFO/Process-6] process shutting down\n",
      "[INFO/Process-7] process shutting down\n",
      "[INFO/Process-6] process shutting down\n",
      "[DEBUG/Process-7] running all \"atexit\" finalizers with priority >= 0\n",
      "[DEBUG/Process-6] running all \"atexit\" finalizers with priority >= 0\n",
      "[INFO/Process-5] process shutting down\n",
      "[DEBUG/Process-7] running all \"atexit\" finalizers with priority >= 0\n",
      "[DEBUG/Process-6] running all \"atexit\" finalizers with priority >= 0\n",
      "[INFO/Process-5] process shutting down\n",
      "[DEBUG/Process-6] running the remaining \"atexit\" finalizers\n",
      "[DEBUG/Process-6] running the remaining \"atexit\" finalizers\n",
      "[INFO/Process-8] process shutting down\n",
      "[INFO/Process-8] process shutting down\n",
      "[DEBUG/Process-5] running all \"atexit\" finalizers with priority >= 0\n",
      "Process Process-6:\n",
      "[DEBUG/Process-7] running the remaining \"atexit\" finalizers\n",
      "[DEBUG/Process-7] running the remaining \"atexit\" finalizers\n",
      "[DEBUG/Process-8] running all \"atexit\" finalizers with priority >= 0\n",
      "[DEBUG/Process-8] running all \"atexit\" finalizers with priority >= 0\n",
      "[DEBUG/Process-5] running all \"atexit\" finalizers with priority >= 0\n",
      "Process Process-7:\n",
      "[DEBUG/Process-8] running the remaining \"atexit\" finalizers\n",
      "[DEBUG/Process-8] running the remaining \"atexit\" finalizers\n",
      "[DEBUG/Process-5] running the remaining \"atexit\" finalizers\n",
      "[DEBUG/Process-5] running the remaining \"atexit\" finalizers\n",
      "Process Process-8:\n",
      "Process Process-5:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pkorobov/opt/anaconda3/envs/rl/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/pkorobov/opt/anaconda3/envs/rl/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/pkorobov/repos/wordle/env_batch.py\", line 135, in worker\n",
      "    cmd, action = worker_connection.recv()\n",
      "  File \"/Users/pkorobov/opt/anaconda3/envs/rl/lib/python3.9/multiprocessing/connection.py\", line 255, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/Users/pkorobov/opt/anaconda3/envs/rl/lib/python3.9/multiprocessing/connection.py\", line 419, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/pkorobov/opt/anaconda3/envs/rl/lib/python3.9/multiprocessing/connection.py\", line 384, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/Users/pkorobov/opt/anaconda3/envs/rl/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/pkorobov/opt/anaconda3/envs/rl/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/pkorobov/opt/anaconda3/envs/rl/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/pkorobov/repos/wordle/env_batch.py\", line 135, in worker\n",
      "    cmd, action = worker_connection.recv()\n",
      "  File \"/Users/pkorobov/opt/anaconda3/envs/rl/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      " 13%|███████▌                                                   | 3216/25001 [1:59:13<13:27:40,  2.22s/it]args, **self._kwargs)\n",
      "  File \"/Users/pkorobov/opt/anaconda3/envs/rl/lib/python3.9/multiprocessing/connection.py\", line 255, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/Users/pkorobov/opt/anaconda3/envs/rl/lib/python3.9/multiprocessing/connection.py\", line 419, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/pkorobov/opt/anaconda3/envs/rl/lib/python3.9/multiprocessing/connection.py\", line 384, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/Users/pkorobov/repos/wordle/env_batch.py\", line 135, in worker\n",
      "    cmd, action = worker_connection.recv()\n",
      "  File \"/Users/pkorobov/opt/anaconda3/envs/rl/lib/python3.9/multiprocessing/connection.py\", line 255, in recv\n",
      "    buf = self._recv_bytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/pkorobov/opt/anaconda3/envs/rl/lib/python3.9/multiprocessing/connection.py\", line 419, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/pkorobov/opt/anaconda3/envs/rl/lib/python3.9/multiprocessing/connection.py\", line 384, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pkorobov/opt/anaconda3/envs/rl/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/pkorobov/opt/anaconda3/envs/rl/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/pkorobov/repos/wordle/env_batch.py\", line 135, in worker\n",
      "    cmd, action = worker_connection.recv()\n",
      "  File \"/Users/pkorobov/opt/anaconda3/envs/rl/lib/python3.9/multiprocessing/connection.py\", line 255, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/Users/pkorobov/opt/anaconda3/envs/rl/lib/python3.9/multiprocessing/connection.py\", line 419, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/pkorobov/opt/anaconda3/envs/rl/lib/python3.9/multiprocessing/connection.py\", line 384, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "[INFO/Process-8] process exiting with exitcode 1\n",
      "[INFO/Process-5] process exitin\n",
      "g with exitcode 1\n",
      "[INFO/Process-8] process exiting with exitcode 1\n",
      "[INFO/Process-5] process exiting with exitcode 1\n",
      "[INFO/Process-6] process exiting with exitcode 1\n",
      "[INFO/Process-6] process exiting with exitcode 1\n",
      "[INFO/Process-7] process exiting with exitcode 1\n",
      "[INFO/Process-7] process exiting with exitcode 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m step \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      6\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(a2c\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_weights/step_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[43ma2c\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36mA2C.train\u001b[0;34m(self, runner)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, runner):\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# collect trajectory using runner\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;66;03m# compute loss and perform one step of gradient optimization\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# do not forget to clip gradients\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     trajectory \u001b[38;5;241m=\u001b[39m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     53\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(trajectory, runner\u001b[38;5;241m.\u001b[39mwrite)\n",
      "File \u001b[0;32m~/repos/wordle/runners.py:44\u001b[0m, in \u001b[0;36mEnvRunner.get_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnsteps):\n\u001b[1;32m     43\u001b[0m     observations\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_observation)\n\u001b[0;32m---> 44\u001b[0m     act \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatest_observation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactions\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m act:\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult of policy.act must contain \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactions\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     48\u001b[0m                          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut has keys \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(act\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/repos/wordle/model.py:263\u001b[0m, in \u001b[0;36mRNNAgent.act\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mLongTensor(inputs)\n\u001b[1;32m    262\u001b[0m letter_tokens, state_tokens \u001b[38;5;241m=\u001b[39m inputs[:, \u001b[38;5;241m0\u001b[39m, :], inputs[:, \u001b[38;5;241m1\u001b[39m, :]\n\u001b[0;32m--> 263\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mletter_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rl/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/repos/wordle/model.py:233\u001b[0m, in \u001b[0;36mRNNAgent.forward\u001b[0;34m(self, letter_seq, state_seq)\u001b[0m\n\u001b[1;32m    230\u001b[0m word_mask \u001b[38;5;241m=\u001b[39m word_mask \u001b[38;5;241m&\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame_voc_matrix[:, t \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m actions_t\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    232\u001b[0m \u001b[38;5;66;03m# keep which words are acceptable\u001b[39;00m\n\u001b[0;32m--> 233\u001b[0m cur_log_probs \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions_t\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-12\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# letters_allowed_count = allowed_letters.sum(axis=-1)\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m# log_probs[letters_allowed_count > 1] += cur_log_probs[letters_allowed_count > 1]\u001b[39;00m\n\u001b[1;32m    237\u001b[0m log_probs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m cur_log_probs\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rl/lib/python3.9/traceback.py:197\u001b[0m, in \u001b[0;36mformat_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    196\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[0;32m--> 197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m format_list(\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rl/lib/python3.9/traceback.py:211\u001b[0m, in \u001b[0;36mextract_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[0;32m--> 211\u001b[0m stack \u001b[38;5;241m=\u001b[39m \u001b[43mStackSummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwalk_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m stack\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stack\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rl/lib/python3.9/traceback.py:362\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[0;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[1;32m    359\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(FrameSummary(\n\u001b[1;32m    360\u001b[0m         filename, lineno, name, lookup_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39mf_locals))\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m fnames:\n\u001b[0;32m--> 362\u001b[0m     \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckcache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;66;03m# If immediate lookup was desired, trigger lookups now.\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lookup_lines:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rl/lib/python3.9/site-packages/IPython/core/compilerop.py:193\u001b[0m, in \u001b[0;36mcheck_linecache_ipython\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m\"\"\"Call linecache.checkcache() safely protecting our cached values.\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;66;03m# First call the original checkcache as intended\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkcache_ori\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# Then, update back the cache with our data, so that tracebacks related\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# to our compiled codes can be produced.\u001b[39;00m\n\u001b[1;32m    196\u001b[0m linecache\u001b[38;5;241m.\u001b[39mcache\u001b[38;5;241m.\u001b[39mupdate(linecache\u001b[38;5;241m.\u001b[39m_ipython_cache)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rl/lib/python3.9/linecache.py:72\u001b[0m, in \u001b[0;36mcheckcache\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m   \u001b[38;5;66;03m# no-op for files loaded via a __loader__\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m     stat \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     cache\u001b[38;5;241m.\u001b[39mpop(filename, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "obs = env.reset()\n",
    "for step in trange(0, total_steps + 1, nenvs * nsteps):\n",
    "    if step % 1000 == 0 and step > 0:\n",
    "        torch.save(a2c.policy.state_dict(), f\"model_weights/step_{step}\")\n",
    "\n",
    "    a2c.train(runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc74c9c8-0158-4ad9-9ef5-0a328e306afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(policy.state_dict(), 'model_weights/better_policy.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8e8bf7-c8f4-47c7-bfed-a1ef37fdb057",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b3b973-dc2d-43d3-a9fa-9ef80d1df4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55888994-b793-4da1-87c0-0204bdc06979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test get_allowed_letters\n",
    "from wrappers import SequenceWrapper, ReshapeWrapper\n",
    "from wrappers import nature_dqn_env\n",
    "\n",
    "num_letters = 29\n",
    "\n",
    "env = WordleEnv()\n",
    "env = SequenceWrapper(env, sos_token=1)\n",
    "env = ReshapeWrapper(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4781f47-7dc5-4903-8394-9f72ec6043df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform2word(word_vector):\n",
    "    letter_list = list(map(lambda x: env.tokenizer.index2letter[x], word_vector))\n",
    "    return ''.join(letter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e0685f9-ff84-4cfc-9881-719a2dd826c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = RNNAgent(\n",
    "    len(tokenizer.index2letter), \n",
    "    len(tokenizer.index2guess_state), \n",
    "    64, 32, \n",
    "    len(tokenizer.index2letter), \n",
    "    output_len=5, \n",
    "    sos_token=1, \n",
    "    game_voc_matrix=game_voc_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b5dcc3e-8899-47bb-bd7c-b172543b9b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PAD>': 0,\n",
       " '<SOS>': 1,\n",
       " '<EOS>': 2,\n",
       " '<RIGHT>': 3,\n",
       " '<CONTAINED>': 4,\n",
       " '<MISS>': 5}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.guess_state2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9825ef0-79c0-4092-8b1e-55121701971a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real word: snail\n",
      "2\n",
      "[[[ 1 21 22  3 21 10  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "    0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  [ 1  3  5  3  5  5  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "    0  0  0  0  0  0  0  0  0  0  0  0  0]]]\n",
      "guess: stash, reward: 0.8\n",
      "3\n",
      "[[[ 1 21 22  3 21 10  1 21 14 17 17 18  1  0  0  0  0  0  0  0  0  0  0\n",
      "    0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  [ 1  3  5  3  5  5  1  3  5  5  5  4  1  0  0  0  0  0  0  0  0  0  0\n",
      "    0  0  0  0  0  0  0  0  0  0  0  0  0]]]\n",
      "guess: sloop, reward: 0.4\n",
      "5\n",
      "[[[ 1 21 22  3 21 10  1 21 14 17 17 18  1 21 16 11 20 22  1  0  0  0  0\n",
      "    0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  [ 1  3  5  3  5  5  1  3  5  5  5  4  1  3  3  5  4  5  1  0  0  0  0\n",
      "    0  0  0  0  0  0  0  0  0  0  0  0  0]]]\n",
      "guess: snirt, reward: 0.8\n",
      "7\n",
      "[[[ 1 21 22  3 21 10  1 21 14 17 17 18  1 21 16 11 20 22  1 21 16 11  9\n",
      "   21  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  [ 1  3  5  3  5  5  1  3  5  5  5  4  1  3  3  5  4  5  1  3  3  5  4\n",
      "    5  1  0  0  0  0  0  0  0  0  0  0  0]]]\n",
      "guess: snigs, reward: 0.6000000000000001\n",
      "8\n",
      "[[[ 1 21 22  3 21 10  1 21 14 17 17 18  1 21 16 11 20 22  1 21 16 11  9\n",
      "   21  1 21 11  5  7 21  1  0  0  0  0  0]\n",
      "  [ 1  3  5  3  5  5  1  3  5  5  5  4  1  3  3  5  4  5  1  3  3  5  4\n",
      "    5  1  3  5  5  4  5  1  0  0  0  0  0]]]\n",
      "guess: sices, reward: 0.2\n",
      "0\n",
      "[[[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "   0]\n",
      "  [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "   0]]]\n",
      "guess: split, reward: 0.6000000000000001\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "\n",
    "env_word = env.word\n",
    "print(f\"Real word: {transform2word(env.word)}\")\n",
    "\n",
    "for _ in range(6):\n",
    "    action = a2c.policy.act(obs)['actions'].squeeze()\n",
    "    obs, rew, done, info = env.step(action)\n",
    "    print((obs[:, 1, :] == 3).sum())\n",
    "    print(obs)\n",
    "    print(f\"guess: {transform2word(action)}, reward: {rew[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07818d5b-a509-4d46-807d-a86e711740e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02fa60ef-8bf7-4e14-8d49-e78efd138e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real word: inlet\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "env_word = env.word\n",
    "print(f\"Real word: {transform2word(env.word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef138a4-b92f-44f9-8b36-f8d472141536",
   "metadata": {},
   "outputs": [],
   "source": [
    "action = np.array([6, 6, v, 8, 8])\n",
    "obs, rew, done, info = env.step(action)\n",
    "print(f\"guess: {transform2word(action)}, reward: {rew[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec6d3fd-7740-4fa0-afec-690a8f955556",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a891ad67-80b4-4df9-b1ee-f40f735e1e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2617aa06-2465-49f8-b8c4-dd22ff2d5657",
   "metadata": {},
   "outputs": [],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b203c21b-e3e6-4c28-8caf-144ffc05dabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "action == env_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf89faf-806d-4df5-b098-1a714f96c7a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c3cbb3-3f86-4d89-abce-e8c2d998e4d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3705751-1a4f-42a8-a8a7-ba91a1d02c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9b2d13-6ceb-4230-bb08-28d2f54b5811",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "done = False\n",
    "\n",
    "print(f\"True word: {transform2word(env.word)}\")\n",
    "\n",
    "print(\"guesses:\")\n",
    "print(\"--------\")\n",
    "\n",
    "while not done:\n",
    "    action = agent.act(obs)['actions'].squeeze()\n",
    "    obs, rew, done, info = env.step(action)\n",
    "    print(f\"{transform2word(action)} (reward = {rew})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cc5caa-23a1-48d4-831b-0730680f8211",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAME_VOCABULARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba296f7-13d8-4703-9a25-28782034fa2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9f87bc-8a63-4d17-b358-36abc0f929c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843a3d37-2e59-4f37-9c9e-a789d4fd0559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edf51c3-acbc-4ec6-9fdd-980a8c859be0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
