{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ca29be4-2dfb-4c66-adbd-df22d1f80d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from wordle_env import WordleEnv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6f1f613-ce69-44eb-b936-a42e59a93e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7fb691e336a0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab7ae835-d677-49c8-a9a3-3e5c55a6afd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dba69c13-dd8c-4077-8d8c-1ceabb702fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_allowed_letters(word_matrix, word_mask, position):\n",
    "    \"\"\"\n",
    "        word_matrix: torch.Tensor of size (num_words, word_length)\n",
    "        word_mask: torch.Tensor of size (batch_size, num_words)\n",
    "        position: int\n",
    "        \n",
    "        returns\n",
    "        \n",
    "        letters_mask: (batch_size, num_letters) -- mask of possible letters\n",
    "    \"\"\"\n",
    "    batch_size = word_mask.size(0)\n",
    "    word_matrix_expanded = word_matrix[:, position].unsqueeze(0).expand(batch_size, -1)\n",
    "    \n",
    "    # print(word_matrix[:, position].shape)\n",
    "    # print(word_matrix_expanded.shape)\n",
    "    # print(word_matrix[:, position].unsqueeze(1).shape)\n",
    "    \n",
    "    word_matrix_masked = (word_matrix_expanded * word_mask).long()    \n",
    "    letter_mask = torch.full(fill_value=False, size=(batch_size, num_letters))\n",
    "\n",
    "    # letter_mask = letter_mask.scatter(index=word_matrix_masked, dim=1, value=True)\n",
    "    rows = torch.arange(0, letter_mask.size(0))[:,None]\n",
    "    n_col = word_matrix_masked.size(1)\n",
    "    letter_mask[rows.repeat(1, n_col), word_matrix_masked] = 1\n",
    "\n",
    "    letter_mask[:, 0] = 0\n",
    "    return letter_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e150594f-d647-4231-8c31-c23f8c4c0953",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Categorical\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, letter_tokens, guess_tokens, emb_dim, hid_dim, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hid_dim = hid_dim\n",
    "        \n",
    "        self.letter_embedding = nn.Embedding(letter_tokens, emb_dim)\n",
    "        self.guess_state_embedding = nn.Embedding(guess_tokens, emb_dim)\n",
    "\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, batch_first=True, num_layers=2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, letter_seq, state_seq):\n",
    "        # letters_embedded = self.dropout(self.letter_embedding(letter_seq))\n",
    "        # states_embedded = self.dropout(self.guess_state_embedding(state_seq))\n",
    "        letters_embedded = self.letter_embedding(letter_seq)\n",
    "        states_embedded = self.guess_state_embedding(state_seq)\n",
    "\n",
    "        outputs, (hidden, cell) = self.rnn(letters_embedded + states_embedded)\n",
    "        \n",
    "        #outputs = [src len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #outputs are always from the top hidden layer\n",
    "        \n",
    "        return hidden, cell\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, dropout=dropout, batch_first=True, num_layers=2)        \n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, cell):\n",
    "        input = input.unsqueeze(1)\n",
    "        # embedded = self.dropout(self.embedding(input))\n",
    "        embedded = self.embedding(input)\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "                \n",
    "        prediction = self.fc_out(output.squeeze(1))\n",
    "        return prediction, hidden, cell\n",
    "\n",
    "\n",
    "\n",
    "class RNNAgent(nn.Module):\n",
    "    def __init__(self, letter_tokens, guess_tokens, emb_dim, hid_dim, output_dim, game_voc_matrix, output_len, sos_token, dropout=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = Encoder(letter_tokens, guess_tokens, emb_dim, hid_dim, dropout)\n",
    "        self.decoder = Decoder(output_dim, emb_dim, hid_dim, dropout)\n",
    "\n",
    "        modules = [nn.Linear(2 * hid_dim, hid_dim), nn.ReLU(), nn.Linear(hid_dim, 1)]\n",
    "        self.V_head = nn.Sequential(*modules)\n",
    "        \n",
    "        self.letter_tokens = letter_tokens\n",
    "        self.game_voc_matrix = game_voc_matrix\n",
    "        self.output_len = output_len\n",
    "        self.sos_token = sos_token\n",
    "    \n",
    "    def forward(self, letter_seq, state_seq):\n",
    "        \"\"\"\n",
    "            inputs:\n",
    "                letter_seq: (batch_size x sequence_length)\n",
    "                state_seq: (batch_size x sequence_length)\n",
    "                \n",
    "            outputs:\n",
    "                \n",
    "        \"\"\"\n",
    "        # tensor to store decoder outputs\n",
    "        batch_size = letter_seq.shape[0]\n",
    "        logits = torch.zeros(batch_size, self.output_len + 1, self.letter_tokens)\n",
    "\n",
    "        hidden, cell = self.encoder(letter_seq, state_seq)\n",
    "        \n",
    "        # compute V\n",
    "        values = self.V_head(hidden.reshape(batch_size, -1))\n",
    "\n",
    "        # first input to the decoder is the <sos> tokens\n",
    "        input = torch.full(size=(batch_size,), fill_value=self.sos_token)\n",
    "        \n",
    "        letter_mask = torch.full(size=(batch_size, self.letter_tokens), fill_value=True)\n",
    "        word_mask = torch.full(size=(batch_size, self.game_voc_matrix.shape[0]), fill_value=True)\n",
    "\n",
    "        # logits: (seq_length, batch_size, num_classes)\n",
    "        \n",
    "        actions = torch.zeros(size=(batch_size, self.output_len), dtype=torch.long)\n",
    "        log_probs = torch.zeros(size=(batch_size,))\n",
    "        for t in range(1, self.output_len + 1):\n",
    "\n",
    "            # cur_logits: (batch_size, num_classes)\n",
    "            # actions: (batch_size,)\n",
    "            cur_logits, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            logits[:, t, :] = cur_logits\n",
    "\n",
    "            probs = F.softmax(cur_logits, dim=-1)\n",
    "\n",
    "            allowed_letters = get_allowed_letters(self.game_voc_matrix, word_mask, t-1)            \n",
    "            probs = torch.where(allowed_letters, probs, torch.zeros_like(probs))\n",
    "            probs = probs / probs.sum(dim=-1, keepdim=True)\n",
    "            # torch.where(<your_tensor> != 0, <tensor with zeroz>, <tensor with the value>)\n",
    "            actions_t = Categorical(probs=probs).sample()\n",
    "            \n",
    "            word_mask = word_mask & (self.game_voc_matrix[:, t - 1].unsqueeze(0) == actions_t.unsqueeze(1))\n",
    "\n",
    "            # keep which words are acceptable\n",
    "            cur_log_probs = torch.log(probs[range(batch_size), actions_t].clip(min=1e-12)).squeeze()\n",
    "\n",
    "            # letters_allowed_count = allowed_letters.sum(axis=-1)\n",
    "            # log_probs[letters_allowed_count > 1] += cur_log_probs[letters_allowed_count > 1]\n",
    "            log_probs += cur_log_probs\n",
    "            \n",
    "            actions[:, t-1] = actions_t\n",
    "            input = actions_t\n",
    "\n",
    "        return {\n",
    "            \"actions\": actions.cpu().numpy(),\n",
    "            # \"logits\": logits,\n",
    "            \"log_probs\": log_probs,\n",
    "            \"values\": values.squeeze(),\n",
    "        }\n",
    "    \n",
    "    def act(self, inputs):\n",
    "        '''\n",
    "        input:\n",
    "            inputs - numpy array, (batch_size x sequences x sequence_length)\n",
    "        output: dict containing keys ['actions', 'logits', 'log_probs', 'values']:\n",
    "            'actions' - selected actions, numpy, (batch_size, sequence_length)\n",
    "            'log_probs' - log probs of selected actions, tensor, (batch_size)\n",
    "            'values' - critic estimations, tensor, (batch_size)\n",
    "        '''\n",
    "        inputs = torch.LongTensor(inputs)\n",
    "        letter_tokens, state_tokens = inputs[:, 0, :], inputs[:, 1, :]\n",
    "        outputs = self(letter_tokens, state_tokens)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504c194a-642f-40cb-8442-c22ffd19b1ad",
   "metadata": {},
   "source": [
    "### Debug part beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0f0b37bd-961a-478b-9846-e96dfea6738f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Level 5/MainProcess] finalizer calling <function close_fds at 0x7fb660344d30> with args [183, 188] and kwargs {}\n",
      "[Level 5/MainProcess] finalizer calling <function close_fds at 0x7fb660344d30> with args [184, 187] and kwargs {}\n",
      "[Level 5/MainProcess] finalizer calling <function close_fds at 0x7fb660344d30> with args [186, 192] and kwargs {}\n",
      "[Level 5/MainProcess] finalizer calling <function close_fds at 0x7fb660344d30> with args [185, 190] and kwargs {}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[INFO/Process-28] child process calling self.run()\n",
      "[INFO/Process-26] child process calling self.run()\n",
      "[INFO/Process-26] child process calling self.run()\n",
      "[INFO/Process-28] child process calling self.run()\n",
      "[INFO/Process-25] child process calling self.run()\n",
      "[INFO/Process-25] child process calling self.run()\n",
      "[INFO/Process-27] child process calling self.run()\n",
      "[INFO/Process-27] child process calling self.run()\n",
      "[DEBUG/MainProcess] created semlock with handle 177\n",
      "[DEBUG/MainProcess] created semlock with handle 181\n",
      "[DEBUG/MainProcess] created semlock with handle 190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "         0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test get_allowed_letters\n",
    "from wrappers import SequenceWrapper, ReshapeWrapper\n",
    "from wrappers import nature_dqn_env\n",
    "\n",
    "num_letters = 29\n",
    "\n",
    "# env = WordleEnv()\n",
    "# env = SequenceWrapper(env, sos_token=1)\n",
    "# env = ReshapeWrapper(env)\n",
    "env = nature_dqn_env(nenvs=4)\n",
    "\n",
    "word_mask = torch.tensor([[False] * env.game_voc_matrix.shape[0], [False] * env.game_voc_matrix.shape[0]])\n",
    "\n",
    "word_mask[0, 3] = True\n",
    "word_mask[1, 7000] = True\n",
    "\n",
    "# a = torch.tensor([[0, 1, 0, 0],\n",
    "#                   [0, 0, 1, 0]])\n",
    "\n",
    "# idx = torch.tensor([[1, 1, 2, 3, 3],\n",
    "#                     [0, 0, 1, 2, 2]])\n",
    "\n",
    "# rows = torch.arange(0, a.size(0))[:,None]\n",
    "# n_col = idx.size(1)\n",
    "# a[rows.repeat(1, n_col), idx] = 1\n",
    "\n",
    "present_letters = get_allowed_letters(\n",
    "    torch.from_numpy(env.game_voc_matrix), \n",
    "    word_mask, \n",
    "    3\n",
    ").to(torch.long)\n",
    "present_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "27a30bcd-6368-4200-99eb-6ab30b9b2ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, 22],\n",
       "        [ 1, 11]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "present_letters.nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d6fb48d8-5268-45fe-9f1c-0ba41c6e3843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.tokenizer.index2letter[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7206be2f-47ef-4bad-b415-9a2c91ee32d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.tokenizer.index2letter[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b0dcdfee-2bb4-45d3-88f3-341a2046e702",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/allowed_words.txt', 'r') as f:\n",
    "    GAME_VOCABULARY = f.read().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "057b384e-3f77-4b9e-b958-53e5589453ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aarti'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GAME_VOCABULARY[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "471f3cca-e5d7-42ea-9102-fa5d26ce9f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mitis'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GAME_VOCABULARY[7000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "599f579b-aec7-4ff9-af16-405db1fa143b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizer import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "game_voc_matrix = torch.FloatTensor(env.game_voc_matrix)\n",
    "agent = RNNAgent(len(tokenizer.index2letter), len(tokenizer.index2guess_state), 64, 32, len(tokenizer.index2letter), output_len=5, sos_token=1, game_voc_matrix=game_voc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "73882ab9-d8e6-483b-a0e9-8ff78a071748",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9a5eae8e-4d49-4432-b06e-aac5559251b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2, 36)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "59a8b101-c082-46ec-ad81-0bfccb6d950a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([array([[28, 17,  5,  5, 17],\n",
       "       [25, 20, 17, 22, 10],\n",
       "       [20,  7, 21, 22, 17],\n",
       "       [14,  7, 21, 22, 21]]), tensor([ -8.0425,  -9.1397, -11.3049,  -9.5118], grad_fn=<AddBackward0>), tensor([-0.0525, -0.0525, -0.0968, -0.0968], grad_fn=<SqueezeBackward0>)])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "\n",
    "letter_tokens = torch.LongTensor(obs[:, 0, :])\n",
    "state_tokens = torch.LongTensor(obs[:, 1, :])\n",
    "\n",
    "agent_output = agent(letter_tokens, state_tokens).values()\n",
    "agent_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ac1a83-f831-4911-9cb9-f2a3896d40d1",
   "metadata": {},
   "source": [
    "### Debug part end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d5e5f6ed-b419-4cda-abeb-e4b69aaadef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG/MainProcess] Queue._start_thread()\n",
      "[DEBUG/MainProcess] doing self._thread.start()\n",
      "[DEBUG/MainProcess] starting thread to feed data to pipe\n",
      "[DEBUG/MainProcess] ... done self._thread.start()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory keys: dict_keys(['actions', 'log_probs', 'values', 'observations', 'rewards', 'dones'])\n",
      "Trajectory rewards: [array([0., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 0.]), array([0., 0., 0., 0.]), array([0., 0., 1., 1.]), array([0., 0., 1., 0.])]\n",
      "Trajectory values: [tensor([-0.0525, -0.0525, -0.0968, -0.0968], grad_fn=<SqueezeBackward0>), tensor([-0.0525, -0.0525, -0.0968, -0.0968], grad_fn=<SqueezeBackward0>), tensor([-0.0525, -0.0525, -0.0968, -0.0968], grad_fn=<SqueezeBackward0>), tensor([-0.0523, -0.0524, -0.0968, -0.0969], grad_fn=<SqueezeBackward0>), tensor([-0.0517, -0.0521, -0.0970, -0.0969], grad_fn=<SqueezeBackward0>), tensor([-0.0506, -0.0532, -0.0971, -0.0995], grad_fn=<SqueezeBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "from runners import EnvRunner\n",
    "\n",
    "runner = EnvRunner(env, agent, nsteps=6)\n",
    "\n",
    "trajectory = runner.get_next()\n",
    "print(f\"Trajectory keys: {trajectory.keys()}\")\n",
    "print(f\"Trajectory rewards: {trajectory['rewards']}\")\n",
    "print(f\"Trajectory values: {trajectory['values']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "100440ad-20f6-4a7c-861d-69f0c610b129",
   "metadata": {},
   "outputs": [],
   "source": [
    "nenvs = 4\n",
    "\n",
    "# Sanity checks\n",
    "# assert 'logits' in trajectory, \"Not found: policy didn't provide logits\"\n",
    "assert 'log_probs' in trajectory, \"Not found: policy didn't provide log_probs of selected actions\"\n",
    "assert 'values' in trajectory, \"Not found: policy didn't provide critic estimations\"\n",
    "# assert trajectory['logits'][0].shape == (nenvs, n_actions), \"logits wrong shape\"\n",
    "assert trajectory['log_probs'][0].shape == (nenvs,), \"log_probs wrong shape\"\n",
    "assert trajectory['values'][0].shape == (nenvs,), \"values wrong shape\"\n",
    "\n",
    "for key in trajectory.keys():\n",
    "    assert len(trajectory[key]) == 6, \\\n",
    "    f\"something went wrong: 6 steps should have been done, got trajectory of length {len(trajectory[key])} for '{key}'\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "759a1871-242f-4b54-9c90-97f460977fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectory['values'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88e19c1-f4fb-4784-abd3-28c3f48d545b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "30655394-01cf-4f27-ac5b-b9be27aa8e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComputeValueTargets:\n",
    "    def __init__(self, policy, gamma=0.99):\n",
    "        self.policy = policy\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def __call__(self, trajectory, latest_observation):\n",
    "        '''\n",
    "        This method should modify trajectory inplace by adding \n",
    "        an item with key 'value_targets' to it\n",
    "        \n",
    "        input:\n",
    "            trajectory - dict from runner\n",
    "            latest_observation - last state, numpy, (num_envs x channels x width x height)\n",
    "        '''\n",
    "        T = len(trajectory['rewards'])\n",
    "        targets = [None] * T\n",
    "        R = self.policy.act(latest_observation)['values']\n",
    "        for t in range(T - 1, -1, -1):\n",
    "            rewards = torch.FloatTensor(trajectory['rewards'][t]).to(DEVICE)\n",
    "            dones = torch.LongTensor(trajectory['dones'][t]).to(DEVICE)\n",
    "            R = rewards + (1 - dones) * self.gamma * R\n",
    "            targets[t] = R\n",
    "        trajectory['value_targets'] = targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5e93e36f-dedd-4821-bc24-e63ae6564447",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MergeTimeBatch:\n",
    "    \"\"\" Merges first two axes typically representing time and env batch. \"\"\"\n",
    "    def __call__(self, trajectory, latest_observation):\n",
    "        trajectory['log_probs'] = torch.cat(trajectory['log_probs'], dim=0)\n",
    "        trajectory['values'] = torch.cat(trajectory['values'], dim=0)        \n",
    "        trajectory['value_targets'] = torch.cat(trajectory['value_targets'], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "88ec9d2f-982b-4a4c-9804-b803b7178362",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = EnvRunner(env, agent, nsteps=6, transforms=[ComputeValueTargets(agent),\n",
    "                                                      MergeTimeBatch()])\n",
    "trajectory = runner.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5c14f2b9-3c6d-4f47-abbd-7a552da1e1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "class A2C:\n",
    "    def __init__(self, policy, optimizer, value_loss_coef=0.25, entropy_coef=0.01, max_grad_norm=0.5):\n",
    "        self.policy = policy\n",
    "        self.optimizer = optimizer\n",
    "        self.value_loss_coef = value_loss_coef\n",
    "        self.entropy_coef = entropy_coef\n",
    "        self.max_grad_norm = max_grad_norm\n",
    "    \n",
    "    def loss(self, trajectory, write):\n",
    "        # compute all losses\n",
    "        # do not forget to use weights for critic loss and entropy loss\n",
    "\n",
    "        targets = trajectory['value_targets'].to(DEVICE).detach()\n",
    "        values = trajectory['values'].to(DEVICE)\n",
    "        log_probs = trajectory['log_probs'].to(DEVICE)\n",
    "        value_loss = (targets - values).pow(2).mean()\n",
    "        \n",
    "        # TODO: recompute\n",
    "        entropy_loss = 0.0 # (log_probs * torch.exp(log_probs)).mean()\n",
    "        \n",
    "        advantage = (targets - values).detach()\n",
    "        policy_loss = -(log_probs * advantage).mean()\n",
    "        \n",
    "        \n",
    "        # log all losses\n",
    "        write('losses', {\n",
    "            'policy loss': policy_loss,\n",
    "            'critic loss': value_loss,\n",
    "            'entropy loss': entropy_loss\n",
    "        })\n",
    "        \n",
    "        # additional logs\n",
    "        write('critic/advantage', advantage.mean())\n",
    "        write('critic/values', {\n",
    "            'value predictions': values.mean(),\n",
    "            'value targets': targets.mean(),\n",
    "        })\n",
    "        \n",
    "        # return scalar loss\n",
    "        return policy_loss + self.value_loss_coef * value_loss + self.entropy_coef * entropy_loss               \n",
    "\n",
    "    def train(self, runner):\n",
    "        # collect trajectory using runner\n",
    "        # compute loss and perform one step of gradient optimization\n",
    "        # do not forget to clip gradients\n",
    "        \n",
    "        trajectory = runner.get_next()\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        loss = self.loss(trajectory, runner.write)\n",
    "        loss.backward()\n",
    "        grad_norm = clip_grad_norm_(self.policy.parameters(), self.max_grad_norm)\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        runner.write('gradient norm', grad_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4c361901-50ac-439b-8854-3852149c8a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO/Process-26] process shutting down\n",
      "[INFO/Process-27] process shutting down\n",
      "[INFO/Process-26] process shutting down\n",
      "[INFO/Process-27] process shutting down\n",
      "[INFO/Process-25] process shutting down\n",
      "[INFO/Process-25] process shutting down\n",
      "[DEBUG/Process-26] running all \"atexit\" finalizers with priority >= 0\n",
      "[DEBUG/Process-27] running all \"atexit\" finalizers with priority >= 0\n",
      "[DEBUG/Process-26] running all \"atexit\" finalizers with priority >= 0\n",
      "[DEBUG/Process-27] running all \"atexit\" finalizers with priority >= 0\n",
      "[DEBUG/Process-25] running all \"atexit\" finalizers with priority >= 0\n",
      "[DEBUG/Process-25] running all \"atexit\" finalizers with priority >= 0\n",
      "[DEBUG/Process-26] running the remaining \"atexit\" finalizers\n",
      "[DEBUG/Process-27] running the remaining \"atexit\" finalizers\n",
      "[DEBUG/Process-26] running the remaining \"atexit\" finalizers\n",
      "[DEBUG/Process-27] running the remaining \"atexit\" finalizers\n",
      "[DEBUG/Process-25] running the remaining \"atexit\" finalizers\n",
      "[DEBUG/Process-25] running the remaining \"atexit\" finalizers\n",
      "[INFO/Process-26] process exiting with exitcode 0\n",
      "[INFO/Process-27] process exiting with exitcode 0\n",
      "[INFO/Process-26] process exiting with exitcode 0\n",
      "[INFO/Process-27] process exiting with exitcode 0\n",
      "[INFO/Process-25] process exiting with exitcode 0\n",
      "[INFO/Process-25] process exiting with exitcode 0\n",
      "[INFO/Process-28] process shutting down\n",
      "[INFO/Process-28] process shutting down\n",
      "[DEBUG/Process-28] running all \"atexit\" finalizers with priority >= 0\n",
      "[DEBUG/Process-28] running all \"atexit\" finalizers with priority >= 0\n",
      "[DEBUG/Process-28] running the remaining \"atexit\" finalizers\n",
      "[DEBUG/Process-28] running the remaining \"atexit\" finalizers\n",
      "[INFO/Process-28] process exiting with exitcode 0\n",
      "[INFO/Process-28] process exiting with exitcode 0\n"
     ]
    }
   ],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a067a006-8a35-41ed-bc87-ffdad564182d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "[INFO/Process-32] child process calling self.run()\n",
      "[INFO/Process-32] child process calling self.run()\n",
      "[INFO/Process-31] child process calling self.run()\n",
      "[INFO/Process-31] child process calling self.run()\n",
      "[INFO/Process-30] child process calling self.run()\n",
      "[INFO/Process-30] child process calling self.run()\n",
      "[INFO/Process-29] child process calling self.run()\n",
      "[INFO/Process-29] child process calling self.run()\n",
      "[DEBUG/MainProcess] created semlock with handle 202\n",
      "[DEBUG/MainProcess] created semlock with handle 204\n",
      "[DEBUG/MainProcess] created semlock with handle 211\n"
     ]
    }
   ],
   "source": [
    "from wordle_env import WordleEnv\n",
    "from wrappers import SequenceWrapper, ReshapeWrapper, TensorboardSummaries\n",
    "from wrappers import nature_dqn_env\n",
    "\n",
    "# env = WordleEnv()\n",
    "# env = SequenceWrapper(env, sos_token=1)\n",
    "# env = ReshapeWrapper(env)\n",
    "# env = TensorboardSummaries(env, prefix='wordle')\n",
    "\n",
    "env = nature_dqn_env(nenvs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e2ea46c8-4386-4b33-898d-2a080c08d30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Level 5/MainProcess] finalizer calling <function close_fds at 0x7fb660344d30> with args [187, 194] and kwargs {}\n",
      "[Level 5/MainProcess] finalizer calling <function close_fds at 0x7fb660344d30> with args [185, 192] and kwargs {}\n",
      "[Level 5/MainProcess] finalizer calling <function close_fds at 0x7fb660344d30> with args [184, 188] and kwargs {}\n",
      "[Level 5/MainProcess] finalizer calling <function close_fds at 0x7fb660344d30> with args [183, 186] and kwargs {}\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import RMSprop\n",
    "\n",
    "nenvs = 4\n",
    "nsteps = 10\n",
    "total_steps = 10 ** 6\n",
    "\n",
    "# env = nature_dqn_env(\"SpaceInvadersNoFrameskip-v4\", nenvs=nenvs)\n",
    "# n_actions = env.action_space.spaces[0].n\n",
    "obs = env.reset()\n",
    "\n",
    "# model = Model(obs.shape[1:], n_actions).to(DEVICE)\n",
    "policy = RNNAgent(\n",
    "    len(tokenizer.index2letter), \n",
    "    len(tokenizer.index2guess_state), \n",
    "    64, 32, \n",
    "    len(tokenizer.index2letter), \n",
    "    output_len=5, \n",
    "    sos_token=1, \n",
    "    game_voc_matrix=game_voc_matrix\n",
    ")\n",
    "\n",
    "runner = EnvRunner(env, policy, nsteps=nsteps, transforms=[ComputeValueTargets(policy),\n",
    "                                                      MergeTimeBatch()])\n",
    "optimizer = RMSprop(policy.parameters(), 7e-4)\n",
    "a2c = A2C(policy, optimizer, max_grad_norm=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f3e96e-2341-4ba6-a778-05ceb5dd6e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                             | 0/25001 [00:00<?, ?it/s][DEBUG/MainProcess] Queue._start_thread()\n",
      "[DEBUG/MainProcess] doing self._thread.start()\n",
      "[DEBUG/MainProcess] starting thread to feed data to pipe\n",
      "[DEBUG/MainProcess] ... done self._thread.start()\n",
      "[DEBUG/MainProcess] created semlock with handle 183\n",
      "[DEBUG/MainProcess] created semlock with handle 184\n",
      "[DEBUG/MainProcess] created semlock with handle 185\n",
      "[DEBUG/MainProcess] Queue._start_thread()\n",
      "[DEBUG/MainProcess] doing self._thread.start()\n",
      "[DEBUG/MainProcess] starting thread to feed data to pipe\n",
      "[DEBUG/MainProcess] ... done self._thread.start()\n",
      "[DEBUG/MainProcess] created semlock with handle 215\n",
      "[DEBUG/MainProcess] created semlock with handle 216\n",
      "[DEBUG/MainProcess] created semlock with handle 217\n",
      "[DEBUG/MainProcess] Queue._start_thread()\n",
      "[DEBUG/MainProcess] doing self._thread.start()\n",
      "[DEBUG/MainProcess] starting thread to feed data to pipe\n",
      "[DEBUG/MainProcess] ... done self._thread.start()\n",
      "[DEBUG/MainProcess] created semlock with handle 223\n",
      "[DEBUG/MainProcess] created semlock with handle 224\n",
      "[DEBUG/MainProcess] created semlock with handle 225\n",
      "[DEBUG/MainProcess] Queue._start_thread()\n",
      "[DEBUG/MainProcess] doing self._thread.start()\n",
      "[DEBUG/MainProcess] starting thread to feed data to pipe\n",
      "[DEBUG/MainProcess] ... done self._thread.start()\n",
      "[DEBUG/MainProcess] created semlock with handle 231\n",
      "[DEBUG/MainProcess] created semlock with handle 232\n",
      "[DEBUG/MainProcess] created semlock with handle 233\n",
      "[DEBUG/MainProcess] Queue._start_thread()\n",
      "[DEBUG/MainProcess] doing self._thread.start()\n",
      "[DEBUG/MainProcess] starting thread to feed data to pipe\n",
      "[DEBUG/MainProcess] ... done self._thread.start()\n",
      "[DEBUG/MainProcess] created semlock with handle 239\n",
      "[DEBUG/MainProcess] created semlock with handle 240\n",
      "[DEBUG/MainProcess] created semlock with handle 241\n",
      "[DEBUG/MainProcess] Queue._start_thread()\n",
      "[DEBUG/MainProcess] doing self._thread.start()\n",
      "[DEBUG/MainProcess] starting thread to feed data to pipe\n",
      "[DEBUG/MainProcess] ... done self._thread.start()\n",
      "  8%|██████████                                                                                                                   | 2007/25001 [1:36:50<22:48:01,  3.57s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "obs = env.reset()\n",
    "for step in trange(0, total_steps + 1, nenvs * nsteps):\n",
    "    a2c.train(runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b3b973-dc2d-43d3-a9fa-9ef80d1df4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55888994-b793-4da1-87c0-0204bdc06979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test get_allowed_letters\n",
    "from wrappers import SequenceWrapper, ReshapeWrapper\n",
    "from wrappers import nature_dqn_env\n",
    "\n",
    "num_letters = 29\n",
    "\n",
    "env = WordleEnv()\n",
    "env = SequenceWrapper(env, sos_token=1)\n",
    "env = ReshapeWrapper(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4781f47-7dc5-4903-8394-9f72ec6043df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform2word(word_vector):\n",
    "    letter_list = list(map(lambda x: env.tokenizer.index2letter[x], word_vector))\n",
    "    return ''.join(letter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c9825ef0-79c0-4092-8b1e-55121701971a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real word: titan\n",
      "ryots [False] [0.]\n",
      "nduja [False] [0.]\n",
      "esnes [False] [0.]\n",
      "today [False] [0.4]\n",
      "gadge [False] [0.]\n",
      "yeeds [ True] [0.]\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "\n",
    "env_word = env.word\n",
    "print(f\"Real word: {transform2word(env.word)}\")\n",
    "\n",
    "for _ in range(6):\n",
    "    action = agent.act(obs)['actions'].squeeze()\n",
    "    obs, rew, done, info = env.step(action)\n",
    "    # print(obs)\n",
    "    print(transform2word(action), done, rew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2617aa06-2465-49f8-b8c4-dd22ff2d5657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20, 23,  4,  4, 27])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b203c21b-e3e6-4c28-8caf-144ffc05dabb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action == env_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf89faf-806d-4df5-b098-1a714f96c7a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c3cbb3-3f86-4d89-abce-e8c2d998e4d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3705751-1a4f-42a8-a8a7-ba91a1d02c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fc9b2d13-6ceb-4230-bb08-28d2f54b5811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True word: mealy\n",
      "guesses:\n",
      "--------\n",
      "zygal (reward = [0.])\n",
      "kydst (reward = [0.])\n",
      "byres (reward = [0.])\n",
      "byrls (reward = [0.2])\n",
      "qanat (reward = [0.])\n",
      "llama (reward = [0.2])\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "done = False\n",
    "\n",
    "print(f\"True word: {transform2word(env.word)}\")\n",
    "\n",
    "print(\"guesses:\")\n",
    "print(\"--------\")\n",
    "\n",
    "while not done:\n",
    "    action = agent.act(obs)['actions'].squeeze()\n",
    "    obs, rew, done, info = env.step(action)\n",
    "    print(f\"{transform2word(action)} (reward = {rew})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cc5caa-23a1-48d4-831b-0730680f8211",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAME_VOCABULARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba296f7-13d8-4703-9a25-28782034fa2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9f87bc-8a63-4d17-b358-36abc0f929c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843a3d37-2e59-4f37-9c9e-a789d4fd0559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edf51c3-acbc-4ec6-9fdd-980a8c859be0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
