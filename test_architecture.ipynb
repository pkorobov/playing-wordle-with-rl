{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c25e895-8720-45f0-9d75-3a427895143a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[DEBUG/MainProcess] created semlock with handle 79\n",
      "[DEBUG/MainProcess] created semlock with handle 80\n",
      "[DEBUG/MainProcess] created semlock with handle 82\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from wordle_env import WordleEnv\n",
    "from wrappers import SequenceWrapper, ReshapeWrapper, TensorboardSummaries\n",
    "from wrappers import nature_dqn_env\n",
    "import numpy as np\n",
    "\n",
    "num_letters = 29\n",
    "\n",
    "env = WordleEnv()\n",
    "env = SequenceWrapper(env, sos_token=1)\n",
    "env = ReshapeWrapper(env)\n",
    "env = TensorboardSummaries(env, prefix='wordle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef1c8ade-d6a7-4b07-9a24-f9cb89ece61b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tokenizer import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.guess_state2index['<RIGHT>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3738c8b4-ea27-4365-aa58-593fbb370aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50b87327-9a24-455b-a6f1-3efa2272d28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ed31bc1-9a6c-439d-a028-de4b0e2923a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4d47bab-4721-4b4e-ac29-a7dd75ee4e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 100000\n",
    "voc_size = len(env.game_ans_matrix)\n",
    "\n",
    "for _ in range(data_size):\n",
    "    idx = np.random.choice(voc_size)\n",
    "    action = env.game_ans_matrix[idx]\n",
    "    obs, rew, done, info = env.step(action)    \n",
    "    data.append(torch.tensor(obs))\n",
    "\n",
    "tensor_data = torch.cat(data, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2500d8e8-8217-4e60-91b0-81e85954303f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(108240)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tensor_data[:, 1, :] == tokenizer.guess_state2index['<RIGHT>']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3eaaec00-607f-4d5c-b001-527475fdac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_letters = tensor_data[:, 0, :][tensor_data[:, 1, :] == tokenizer.guess_state2index['<RIGHT>']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cdcfe00b-385c-40a9-a2ef-95d5af6f1d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = (tensor_data[:, 1, :] == tokenizer.guess_state2index['<RIGHT>']).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "33249930-d6f9-4720-86c6-cb83a59419df",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = []\n",
    "pos = 0\n",
    "\n",
    "for i in range(len(tensor_data)):\n",
    "    targets.append(true_letters[pos:pos + lens[i]])\n",
    "    pos += lens[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "74993848-892a-4e79-882d-560e762980fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_data = tensor_data[lens > 0]\n",
    "targets = pad_sequence(targets, batch_first=True)[lens > 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b547f58-af6c-4879-bd0d-dba19c74d946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([57595, 2, 36])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5cfc2695-f2e8-4e3b-aaac-b7d60f174559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([57595, 9])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c5fe23f8-38c5-497d-82f9-76418fe5c29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = targets[:, :np.quantile(lens, 0.98).astype(np.int64)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "62b7e571-07af-4e8c-80e0-07b8a53aceab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[21,  3,  0,  0],\n",
       "        [21,  3,  0,  0],\n",
       "        [21,  3,  0,  0],\n",
       "        ...,\n",
       "        [22,  0,  0,  0],\n",
       "        [22,  0,  0,  0],\n",
       "        [22,  0,  0,  0]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ad331015-2000-4e07-8af9-c768caf40ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from model import Encoder, Decoder, AttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "e9fbfadc-1ec4-4dfd-bc73-78f0416d7334",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, letter_tokens, guess_tokens, emb_dim, hid_dim, output_dim, game_voc_matrix, output_len, sos_token, dropout=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = Encoder(letter_tokens, guess_tokens, emb_dim, hid_dim, dropout)\n",
    "        self.decoder = Decoder(output_dim, emb_dim, hid_dim, dropout)\n",
    "        self.attention = AttentionLayer(hid_dim)\n",
    "\n",
    "        self.logit_head = nn.Linear(hid_dim, output_dim)\n",
    "        \n",
    "        self.letter_tokens = letter_tokens\n",
    "        self.game_voc_matrix = game_voc_matrix\n",
    "        self.output_len = output_len\n",
    "        self.sos_token = sos_token\n",
    "        self.debug_mode = False\n",
    "\n",
    "    def debug(self, mode=False):\n",
    "        self.debug_mode = mode\n",
    "    \n",
    "    def forward(self, letter_seq, state_seq, targets=None):\n",
    "        \"\"\"\n",
    "            inputs:\n",
    "                letter_seq: (batch_size x sequence_length)\n",
    "                state_seq: (batch_size x sequence_length)\n",
    "                \n",
    "            outputs:\n",
    "                \n",
    "        \"\"\"\n",
    "        \n",
    "        maxlen = letter_seq.shape[1]\n",
    "        lengths = (letter_seq != 0).sum(axis=-1)\n",
    "        mask = (torch.arange(maxlen)[None, :] < lengths[:, None]).bool()\n",
    "\n",
    "        # tensor to store decoder outputs\n",
    "        batch_size = letter_seq.shape[0]\n",
    "        \n",
    "        output_len = self.output_len if targets is None else targets.shape[1]\n",
    "        logits = torch.zeros(batch_size, output_len, self.letter_tokens)\n",
    "\n",
    "        encoder_hiddens, encoder_cells = self.encoder(letter_seq, state_seq)        \n",
    "        hidden, cell = encoder_hiddens[:, -1:, :], encoder_cells[:, -1:, :]\n",
    "        hidden, cell = hidden.permute(dims=(1, 0, 2)), cell.permute(dims=(1, 0, 2))\n",
    "\n",
    "        # first input to the decoder is the <sos> tokens\n",
    "        input = torch.full(size=(batch_size,), fill_value=self.sos_token)\n",
    "        \n",
    "        actions = torch.zeros(size=(batch_size, self.output_len), dtype=torch.long)\n",
    "        log_probs = torch.zeros(size=(batch_size,))\n",
    "        \n",
    "        if self.debug_mode:\n",
    "            fig, ax = plt.subplots(1, self.output_len)\n",
    "        \n",
    "        for t in range(1, output_len):\n",
    "\n",
    "            # cur_logits: (batch_size, num_classes)\n",
    "            # actions: (batch_size,)\n",
    "            _, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            \n",
    "            decoder_hidden = hidden\n",
    "            attentive_hidden = self.attention(encoder_hiddens, decoder_hidden.permute(dims=(1, 0, 2)), encoder_hiddens, mask).squeeze(1)\n",
    "            \n",
    "            if self.debug_mode:\n",
    "                map_reshaped = self.attention.attention_map.squeeze().reshape(6, 6).detach().numpy()\n",
    "                ax[t - 1].imshow(map_reshaped)\n",
    "            \n",
    "            cur_logits = self.logit_head(attentive_hidden)\n",
    "            logits[:, t, :] = cur_logits\n",
    "            \n",
    "            if targets is not None:\n",
    "                input = targets[:, t - 1]\n",
    "            else:\n",
    "                input = cur_logits.argmax(1)\n",
    "                actions[:, t - 1] = input\n",
    "\n",
    "        if self.debug_mode:\n",
    "            plt.show()\n",
    "\n",
    "        return {\n",
    "            \"actions\": actions.cpu().numpy(),\n",
    "            \"logits\": logits,\n",
    "            \"log_probs\": log_probs\n",
    "        }\n",
    "    \n",
    "    def act(self, inputs, targets=None):\n",
    "        '''\n",
    "        input:\n",
    "            inputs - numpy array, (batch_size x sequences x sequence_length)\n",
    "        output: dict containing keys ['actions', 'logits', 'log_probs', 'values']:\n",
    "            'actions' - selected actions, numpy, (batch_size, sequence_length)\n",
    "            'log_probs' - log probs of selected actions, tensor, (batch_size)\n",
    "            'values' - critic estimations, tensor, (batch_size)\n",
    "        '''\n",
    "        inputs = torch.LongTensor(inputs)\n",
    "        letter_tokens, state_tokens = inputs[:, 0, :], inputs[:, 1, :]\n",
    "        outputs = self(letter_tokens, state_tokens, targets)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "7a112f99-2709-4f80-a5df-50959f598e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = Model(\n",
    "    len(tokenizer.index2letter), \n",
    "    len(tokenizer.index2guess_state), \n",
    "    32, 128, \n",
    "    len(tokenizer.index2letter), \n",
    "    output_len=5, \n",
    "    sos_token=1, \n",
    "    game_voc_matrix=env.game_voc_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "8c9a0dcc-3ab2-45e7-a51d-cf3765170e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 4, 29])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.act(tensor_data[:10], targets[:10])['logits'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4d6063-2781-40e6-a958-534990b7fc53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "a963d1dd-ced9-4ab7-91c1-f046a9fd88db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "db9fa4e9-8ff2-494f-823e-fd27ded28928",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(tensor_data, targets)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "3dd4c3df-dd3d-4b1c-9433-01e0ccff6fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(policy.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7884ba7-386c-4ec5-bc79-3d94bcacc6ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "b15bd09b-e9a8-40ed-8cd5-215ec347271e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 1.6858958005905151\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [230]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      7\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(logits\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m), batch_y)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m        \n\u001b[1;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rl/lib/python3.9/site-packages/torch/_tensor.py:255\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    248\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    249\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    253\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    254\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 255\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rl/lib/python3.9/site-packages/torch/autograd/__init__.py:147\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m--> 147\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.letter2index['<PAD>'])\n",
    "\n",
    "for epoch in range(5):\n",
    "    for batch_x, batch_y in loader:\n",
    "        logits = policy.act(batch_x, batch_y)['logits']\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(logits.permute(0, 2, 1), batch_y)\n",
    "        loss.backward()        \n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f\"Loss = {loss.item()}\", end=\"\\r\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "26db856d-d55f-4820-8d31-77775b690dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 36)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "eae88fae-0ba1-46a3-b73d-e959e5524803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  6,  3,  6,  6, 27,  1, 15, 17, 23, 21,  7,  1, 21, 10,  3, 20,\n",
       "          13,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0],\n",
       "         [ 1,  5,  5,  4,  5,  5,  1,  4,  5,  5,  4,  5,  1,  3,  5,  3,  5,\n",
       "           5,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0]]])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "d41f1f5d-94d4-43f9-8094-3ebdc73deec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'actions': array([[7, 7, 7, 7, 0]]),\n",
       " 'logits': tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [-1.7884, -2.0632, -1.2262, -0.1962, -1.5051, -1.7639, -1.2554,\n",
       "            6.2180,  0.4405,  0.0379, -1.8652, -1.0941, -0.4712, -0.4245,\n",
       "           -0.8784, -0.0734,  0.4749,  0.2367, -1.2355, -0.9595, -0.9706,\n",
       "            0.4247, -1.2451, -0.8168,  0.6191, -0.0391, -0.0844, -0.9520,\n",
       "           -1.1403],\n",
       "          [-1.9342, -2.3574, -1.3829,  1.5797, -0.9328, -2.1390, -1.0152,\n",
       "            2.0759,  0.7864,  1.4674, -0.1069,  0.2686, -0.4730, -1.0109,\n",
       "           -0.0904,  0.1697,  0.4819,  0.0960, -1.3320, -0.4715, -1.6435,\n",
       "            0.8346, -2.1798, -0.4123,  0.1721,  0.3797, -0.3087, -0.2949,\n",
       "           -0.6558],\n",
       "          [-1.9321, -2.3566, -1.3816,  1.5982, -0.9257, -2.1407, -1.0115,\n",
       "            2.0280,  0.7887,  1.4806, -0.0875,  0.2830, -0.4728, -1.0170,\n",
       "           -0.0817,  0.1727,  0.4817,  0.0945, -1.3316, -0.4660, -1.6499,\n",
       "            0.8375, -2.1877, -0.4070,  0.1670,  0.3827, -0.3118, -0.2863,\n",
       "           -0.6498],\n",
       "          [-1.9232, -2.3428, -1.3732,  1.5435, -0.9419, -2.1265, -1.0174,\n",
       "            2.1495,  0.7764,  1.4346, -0.1403,  0.2414, -0.4724, -0.9989,\n",
       "           -0.1052,  0.1658,  0.4811,  0.0987, -1.3269, -0.4804, -1.6285,\n",
       "            0.8231, -2.1566, -0.4182,  0.1803,  0.3680, -0.3059, -0.3045,\n",
       "           -0.6636]]], grad_fn=<CopySlices>),\n",
       " 'log_probs': tensor([0.])}"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = np.random.randint(10000)\n",
    "policy.act(tensor_data[i:i + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "338b29b8-5908-4931-bc7d-892fe40a84be",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = tensor_data[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "401e0db2-7328-4ce9-90c3-d29e81160d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs[0, obs[1] == tokenizer.guess_state2index['<RIGHT>']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "fe0f8095-ba5f-4ad8-b974-c145beebb98a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(4 ** 1356 - 9 ** 4824) % 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "5e5e1d71-1992-4d56-a666-ebc13363c9f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(4 ** 6 - 9 ** 24) % 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "0fd5305d-d1f5-4e00-87a2-e49354e226ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2 ** 2 - 3 ** 18) % 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ac7a77-5ed1-4ef2-9262-e738b893466c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29edb29-09d5-4a33-89e9-7b55b3af8eef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1097cb7-367e-4e91-8658-3a5085ed42e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4184cf7f-618d-4ec0-adbc-35e7ec8aa2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b8ebfa40-970b-4d41-9f88-3770c9c4b8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 4, 29])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0f7173-354e-405a-ac94-84dce07d84fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f57de5f-620e-46e3-9ad1-67b5cfe3fd2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9a7bee88-0bc1-46e5-93ac-4d917573bd34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([57595, 4])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11fa55c-d205-4688-9008-840f874d6245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "84e72814-7560-4895-8f89-463d47420837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 3, 3, 0])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[:4, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5608296-370f-4fe5-b4cc-245ab429f2a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd3c656-ca97-4c5f-8d51-d917293553ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9b8c4f-c6b7-4f05-b792-d2a340d7377f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e41a50b-612c-4397-8dd9-9f3652632c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff182b21-5f3e-48fe-b1d7-7634192d902f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
